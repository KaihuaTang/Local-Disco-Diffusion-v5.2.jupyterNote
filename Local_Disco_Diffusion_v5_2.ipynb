{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TitleTop"
   },
   "source": [
    "# 1. Check GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CreditsChTop"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 11 15:07:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:19:00.0 Off |                  N/A |\n",
      "| 32%   44C    P0    61W / 250W |      1MiB / 11019MiB |     19%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   40C    P8     1W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:67:00.0 Off |                  N/A |\n",
      "| 28%   37C    P8    19W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:68:00.0 Off |                  N/A |\n",
      "| 27%   36C    P8     1W / 250W |     26MiB / 11016MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    3      1570      G   /usr/lib/xorg/Xorg                             9MiB |\n",
      "|    3      1644      G   /usr/bin/gnome-shell                          14MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "ECC features not supported for GPU 00000000:19:00.0.\n",
      "Treating as warning and moving on.\n",
      "All done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "#!nvidia-smi -i 0 -e 0\n",
    "nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(nvidiasmi_output)\n",
    "nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(nvidiasmi_ecc_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Credits"
   },
   "source": [
    "# 2. Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LicenseTop"
   },
   "outputs": [],
   "source": [
    "#@title 1.2 Prepare Folders\n",
    "import subprocess, os, sys\n",
    "import pathlib, shutil\n",
    "\n",
    "from utils.utils_os import *\n",
    "from main import do_run\n",
    "\n",
    "# the following paths are same as preprocessing.py\n",
    "root_path = os.getcwd()\n",
    "initDirPath = f'{root_path}/outputs/init_images'\n",
    "outDirPath = f'{root_path}/outputs/images_out'\n",
    "model_path = f'{root_path}/outputs/models'\n",
    "\n",
    "# project directory\n",
    "PROJECT_DIR = os.path.abspath(os.getcwd())\n",
    "sys.path.append(PROJECT_DIR)\n",
    "os.chdir(f'{PROJECT_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "License"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# import all dependencies\n",
    "\n",
    "### preprocess: download absent packages\n",
    "preprocess(model_path, PROJECT_DIR)\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "import io\n",
    "import math\n",
    "import timm\n",
    "from IPython import display\n",
    "import lpips\n",
    "from PIL import Image, ImageOps\n",
    "import requests\n",
    "from glob import glob\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm.notebook import tqdm\n",
    "from CLIP import clip\n",
    "from resize_right import resize\n",
    "from guided_diffusion.script_util import create_model_and_diffusion, model_and_diffusion_defaults\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from ipywidgets import Output\n",
    "import hashlib\n",
    "from functools import partial  \n",
    "from IPython.display import Image as ipyimg\n",
    "from numpy import asarray\n",
    "from einops import rearrange, repeat\n",
    "import torch, torchvision\n",
    "import time\n",
    "from omegaconf import OmegaConf\n",
    "from infer import InferenceHelper\n",
    "\n",
    "\n",
    "from CLIP import clip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# If running locally, there's a good chance your env will need this in order to not crash upon np.matmul() or similar operations.\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "\n",
    "# AdaBins stuff\n",
    "MAX_ADABINS_AREA = 500000\n",
    "\n",
    "# CUDA Device\n",
    "DEVICE = torch.device('cuda:0' if (torch.cuda.is_available()) else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "device = DEVICE # At least one of the modules expects this name..\n",
    "\n",
    "\n",
    "if torch.cuda.get_device_capability(DEVICE) == (8,0): ## A100 fix thanks to Emad\n",
    "    print('Disabling CUDNN for A100 gpu', file=sys.stderr)\n",
    "    torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChangelogTop"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Changelog"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TutorialTop"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DiffusionSet"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SetupTop"
   },
   "source": [
    "# 3. Diffusion and CLIP model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CheckGPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 Model already downloaded, check check_model_SHA if the file is corrupt\n",
      "Secondary Model already downloaded, check check_model_SHA if the file is corrupt\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/kaihua/anaconda3/envs/disco_diffusion/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "#@markdown ####**Models Settings:**\n",
    "diffusion_model = \"512x512_diffusion_uncond_finetune_008100\" #@param [\"256x256_diffusion_uncond\", \"512x512_diffusion_uncond_finetune_008100\"]\n",
    "use_secondary_model = True #@param {type: 'boolean'}\n",
    "diffusion_sampling_mode = 'ddim' #@param ['plms','ddim']  \n",
    "\n",
    "\n",
    "use_checkpoint = True #@param {type: 'boolean'}\n",
    "ViTB32 = True #@param{type:\"boolean\"}\n",
    "ViTB16 = True #@param{type:\"boolean\"}\n",
    "ViTL14 = False #@param{type:\"boolean\"}\n",
    "RN101 = False #@param{type:\"boolean\"}\n",
    "RN50 = True #@param{type:\"boolean\"}\n",
    "RN50x4 = False #@param{type:\"boolean\"}\n",
    "RN50x16 = False #@param{type:\"boolean\"}\n",
    "RN50x64 = False #@param{type:\"boolean\"}\n",
    "\n",
    "#@markdown If you're having issues with model downloads, check this to compare SHA's:\n",
    "check_model_SHA = False #@param{type:\"boolean\"}\n",
    "\n",
    "def download_models(diffusion_model,use_secondary_model,fallback=False):\n",
    "  model_256_downloaded = False\n",
    "  model_512_downloaded = False\n",
    "  model_secondary_downloaded = False\n",
    "\n",
    "  model_256_SHA = '983e3de6f95c88c81b2ca7ebb2c217933be1973b1ff058776b970f901584613a'\n",
    "  model_512_SHA = '9c111ab89e214862b76e1fa6a1b3f1d329b1a88281885943d2cdbe357ad57648'\n",
    "  model_secondary_SHA = '983e3de6f95c88c81b2ca7ebb2c217933be1973b1ff058776b970f901584613a'\n",
    "\n",
    "  model_256_link = 'https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt'\n",
    "  model_512_link = 'https://v-diffusion.s3.us-west-2.amazonaws.com/512x512_diffusion_uncond_finetune_008100.pt'\n",
    "  model_secondary_link = 'https://v-diffusion.s3.us-west-2.amazonaws.com/secondary_model_imagenet_2.pth'\n",
    "\n",
    "  model_256_link_fb = 'https://www.dropbox.com/s/9tqnqo930mpnpcn/256x256_diffusion_uncond.pt'\n",
    "  model_512_link_fb = 'https://huggingface.co/lowlevelware/512x512_diffusion_unconditional_ImageNet/resolve/main/512x512_diffusion_uncond_finetune_008100.pt'\n",
    "  model_secondary_link_fb = 'https://the-eye.eu/public/AI/models/v-diffusion/secondary_model_imagenet_2.pth'\n",
    "\n",
    "  model_256_path = f'{model_path}/256x256_diffusion_uncond.pt'\n",
    "  model_512_path = f'{model_path}/512x512_diffusion_uncond_finetune_008100.pt'\n",
    "  model_secondary_path = f'{model_path}/secondary_model_imagenet_2.pth'\n",
    "\n",
    "  if fallback:\n",
    "    model_256_link = model_256_link_fb\n",
    "    model_512_link = model_512_link_fb\n",
    "    model_secondary_link = model_secondary_link_fb\n",
    "  # Download the diffusion model\n",
    "  if diffusion_model == '256x256_diffusion_uncond':\n",
    "    if os.path.exists(model_256_path) and check_model_SHA:\n",
    "      print('Checking 256 Diffusion File')\n",
    "      with open(model_256_path,\"rb\") as f:\n",
    "          bytes = f.read() \n",
    "          hash = hashlib.sha256(bytes).hexdigest();\n",
    "      if hash == model_256_SHA:\n",
    "        print('256 Model SHA matches')\n",
    "        model_256_downloaded = True\n",
    "      else: \n",
    "        print(\"256 Model SHA doesn't match, redownloading...\")\n",
    "        wget(model_256_link, model_path)\n",
    "        if os.path.exists(model_256_path):\n",
    "          model_256_downloaded = True\n",
    "        else:\n",
    "          print('First URL Failed using FallBack')\n",
    "          download_models(diffusion_model,use_secondary_model,True)\n",
    "    elif os.path.exists(model_256_path) and not check_model_SHA or model_256_downloaded == True:\n",
    "      print('256 Model already downloaded, check check_model_SHA if the file is corrupt')\n",
    "    else:  \n",
    "      wget(model_256_link, model_path)\n",
    "      if os.path.exists(model_256_path):\n",
    "        model_256_downloaded = True\n",
    "      else:\n",
    "        print('First URL Failed using FallBack')\n",
    "        download_models(diffusion_model,True)\n",
    "  elif diffusion_model == '512x512_diffusion_uncond_finetune_008100':\n",
    "    if os.path.exists(model_512_path) and check_model_SHA:\n",
    "      print('Checking 512 Diffusion File')\n",
    "      with open(model_512_path,\"rb\") as f:\n",
    "          bytes = f.read() \n",
    "          hash = hashlib.sha256(bytes).hexdigest();\n",
    "      if hash == model_512_SHA:\n",
    "        print('512 Model SHA matches')\n",
    "        if os.path.exists(model_512_path):\n",
    "          model_512_downloaded = True\n",
    "        else:\n",
    "          print('First URL Failed using FallBack')\n",
    "          download_models(diffusion_model,use_secondary_model,True)\n",
    "      else:  \n",
    "        print(\"512 Model SHA doesn't match, redownloading...\")\n",
    "        wget(model_512_link, model_path)\n",
    "        if os.path.exists(model_512_path):\n",
    "          model_512_downloaded = True\n",
    "        else:\n",
    "          print('First URL Failed using FallBack')\n",
    "          download_models(diffusion_model,use_secondary_model,True)\n",
    "    elif os.path.exists(model_512_path) and not check_model_SHA or model_512_downloaded == True:\n",
    "      print('512 Model already downloaded, check check_model_SHA if the file is corrupt')\n",
    "    else:  \n",
    "      wget(model_512_link, model_path)\n",
    "      model_512_downloaded = True\n",
    "  # Download the secondary diffusion model v2\n",
    "  if use_secondary_model == True:\n",
    "    if os.path.exists(model_secondary_path) and check_model_SHA:\n",
    "      print('Checking Secondary Diffusion File')\n",
    "      with open(model_secondary_path,\"rb\") as f:\n",
    "          bytes = f.read() \n",
    "          hash = hashlib.sha256(bytes).hexdigest();\n",
    "      if hash == model_secondary_SHA:\n",
    "        print('Secondary Model SHA matches')\n",
    "        model_secondary_downloaded = True\n",
    "      else:  \n",
    "        print(\"Secondary Model SHA doesn't match, redownloading...\")\n",
    "        wget(model_secondary_link, model_path)\n",
    "        if os.path.exists(model_secondary_path):\n",
    "          model_secondary_downloaded = True\n",
    "        else:\n",
    "          print('First URL Failed using FallBack')\n",
    "          download_models(diffusion_model,use_secondary_model,True)\n",
    "    elif os.path.exists(model_secondary_path) and not check_model_SHA or model_secondary_downloaded == True:\n",
    "      print('Secondary Model already downloaded, check check_model_SHA if the file is corrupt')\n",
    "    else:  \n",
    "      wget(model_secondary_link, model_path)\n",
    "      if os.path.exists(model_secondary_path):\n",
    "          model_secondary_downloaded = True\n",
    "      else:\n",
    "        print('First URL Failed using FallBack')\n",
    "        download_models(diffusion_model,use_secondary_model,True)\n",
    "\n",
    "download_models(diffusion_model,use_secondary_model)\n",
    "\n",
    "model_config = model_and_diffusion_defaults()\n",
    "if diffusion_model == '512x512_diffusion_uncond_finetune_008100':\n",
    "    model_config.update({\n",
    "        'attention_resolutions': '32, 16, 8',\n",
    "        'class_cond': False,\n",
    "        'diffusion_steps': 1000, #No need to edit this, it is taken care of later.\n",
    "        'rescale_timesteps': True,\n",
    "        'timestep_respacing': 250, #No need to edit this, it is taken care of later.\n",
    "        'image_size': 512,\n",
    "        'learn_sigma': True,\n",
    "        'noise_schedule': 'linear',\n",
    "        'num_channels': 256,\n",
    "        'num_head_channels': 64,\n",
    "        'num_res_blocks': 2,\n",
    "        'resblock_updown': True,\n",
    "        'use_checkpoint': use_checkpoint,\n",
    "        'use_fp16': True,\n",
    "        'use_scale_shift_norm': True,\n",
    "    })\n",
    "elif diffusion_model == '256x256_diffusion_uncond':\n",
    "    model_config.update({\n",
    "        'attention_resolutions': '32, 16, 8',\n",
    "        'class_cond': False,\n",
    "        'diffusion_steps': 1000, #No need to edit this, it is taken care of later.\n",
    "        'rescale_timesteps': True,\n",
    "        'timestep_respacing': 250, #No need to edit this, it is taken care of later.\n",
    "        'image_size': 256,\n",
    "        'learn_sigma': True,\n",
    "        'noise_schedule': 'linear',\n",
    "        'num_channels': 256,\n",
    "        'num_head_channels': 64,\n",
    "        'num_res_blocks': 2,\n",
    "        'resblock_updown': True,\n",
    "        'use_checkpoint': use_checkpoint,\n",
    "        'use_fp16': True,\n",
    "        'use_scale_shift_norm': True,\n",
    "    })\n",
    "\n",
    "model_default = model_config['image_size']\n",
    "\n",
    "\n",
    "\n",
    "if use_secondary_model:\n",
    "    secondary_model = SecondaryDiffusionImageNet2()\n",
    "    secondary_model.load_state_dict(torch.load(f'{model_path}/secondary_model_imagenet_2.pth', map_location='cpu'))\n",
    "    secondary_model.eval().requires_grad_(False).to(device)\n",
    "\n",
    "clip_models = []\n",
    "if ViTB32 is True: clip_models.append(clip.load('ViT-B/32', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if ViTB16 is True: clip_models.append(clip.load('ViT-B/16', jit=False)[0].eval().requires_grad_(False).to(device) ) \n",
    "if ViTL14 is True: clip_models.append(clip.load('ViT-L/14', jit=False)[0].eval().requires_grad_(False).to(device) ) \n",
    "if RN50 is True: clip_models.append(clip.load('RN50', jit=False)[0].eval().requires_grad_(False).to(device))\n",
    "if RN50x4 is True: clip_models.append(clip.load('RN50x4', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN50x16 is True: clip_models.append(clip.load('RN50x16', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN50x64 is True: clip_models.append(clip.load('RN50x64', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN101 is True: clip_models.append(clip.load('RN101', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "\n",
    "normalize = T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
    "lpips_model = lpips.LPIPS(net='vgg').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "PrepFolders"
   },
   "source": [
    "# 4. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "InstallDeps"
   },
   "outputs": [],
   "source": [
    "#@markdown ####**Basic Settings:**\n",
    "batch_name = 'TimeToDisco2' #@param{type: 'string'}\n",
    "steps = 250 #@param [25,50,100,150,250,500,1000]{type: 'raw', allow-input: true}\n",
    "width_height = [768, 1280]#@param{type: 'raw'}\n",
    "clip_guidance_scale = 5000 #@param{type: 'number'}\n",
    "tv_scale =  0#@param{type: 'number'}\n",
    "range_scale =   150#@param{type: 'number'}\n",
    "sat_scale =   0#@param{type: 'number'}\n",
    "cutn_batches = 4  #@param{type: 'number'}\n",
    "skip_augs = False#@param{type: 'boolean'}\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Init Settings:**\n",
    "init_image = None #@param{type: 'string'}\n",
    "init_scale = 1000 #@param{type: 'integer'}\n",
    "skip_steps = 10 #@param{type: 'integer'}\n",
    "#@markdown *Make sure you set skip_steps to ~50% of your steps if you want to use an init image.*\n",
    "\n",
    "#Get corrected sizes\n",
    "side_x = (width_height[0]//64)*64;\n",
    "side_y = (width_height[1]//64)*64;\n",
    "if side_x != width_height[0] or side_y != width_height[1]:\n",
    "  print(f'Changing output size to {side_x}x{side_y}. Dimensions must by multiples of 64.')\n",
    "\n",
    "#Update Model Settings\n",
    "timestep_respacing = f'ddim{steps}'\n",
    "diffusion_steps = (1000//steps)*steps if steps < 1000 else steps\n",
    "model_config.update({\n",
    "    'timestep_respacing': timestep_respacing,\n",
    "    'diffusion_steps': diffusion_steps,\n",
    "})\n",
    "\n",
    "#Make folder for batch\n",
    "batchFolder = f'{outDirPath}/{batch_name}'\n",
    "createPath(batchFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DefMidasFns"
   },
   "source": [
    "### Animation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DefFns"
   },
   "outputs": [],
   "source": [
    "#@markdown ####**Animation Mode:**\n",
    "animation_mode = 'None' #@param ['None', '2D', '3D', 'Video Input'] {type:'string'}\n",
    "#@markdown *For animation, you probably want to turn `cutn_batches` to 1 to make it quicker.*\n",
    "\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Video Input Settings:**\n",
    "video_init_path = \"training.mp4\" #@param {type: 'string'}\n",
    "extract_nth_frame = 2 #@param {type: 'number'}\n",
    "video_init_seed_continuity = True #@param {type: 'boolean'}\n",
    "\n",
    "if animation_mode == \"Video Input\":\n",
    "  videoFramesFolder = f'videoFrames'\n",
    "  createPath(videoFramesFolder)\n",
    "  print(f\"Exporting Video Frames (1 every {extract_nth_frame})...\")\n",
    "  try:\n",
    "    for f in pathlib.Path(f'{videoFramesFolder}').glob('*.jpg'):\n",
    "      f.unlink()\n",
    "  except:\n",
    "    print('')\n",
    "  vf = f'select=not(mod(n\\,{extract_nth_frame}))'\n",
    "  subprocess.run(['ffmpeg', '-i', f'{video_init_path}', '-vf', f'{vf}', '-vsync', 'vfr', '-q:v', '2', '-loglevel', 'error', '-stats', f'{videoFramesFolder}/%04d.jpg'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "  #!ffmpeg -i {video_init_path} -vf {vf} -vsync vfr -q:v 2 -loglevel error -stats {videoFramesFolder}/%04d.jpg\n",
    "\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**2D Animation Settings:**\n",
    "#@markdown `zoom` is a multiplier of dimensions, 1 is no zoom.\n",
    "#@markdown All rotations are provided in degrees.\n",
    "\n",
    "key_frames = True #@param {type:\"boolean\"}\n",
    "max_frames = 10000#@param {type:\"number\"}\n",
    "\n",
    "if animation_mode == \"Video Input\":\n",
    "  max_frames = len(glob(f'{videoFramesFolder}/*.jpg'))\n",
    "\n",
    "interp_spline = 'Linear' #Do not change, currently will not look good. param ['Linear','Quadratic','Cubic']{type:\"string\"}\n",
    "angle = \"0:(0)\"#@param {type:\"string\"}\n",
    "zoom = \"0: (1), 10: (1.05)\"#@param {type:\"string\"}\n",
    "translation_x = \"0: (0)\"#@param {type:\"string\"}\n",
    "translation_y = \"0: (0)\"#@param {type:\"string\"}\n",
    "translation_z = \"0: (10.0)\"#@param {type:\"string\"}\n",
    "rotation_3d_x = \"0: (0)\"#@param {type:\"string\"}\n",
    "rotation_3d_y = \"0: (0)\"#@param {type:\"string\"}\n",
    "rotation_3d_z = \"0: (0)\"#@param {type:\"string\"}\n",
    "midas_depth_model = \"dpt_large\"#@param {type:\"string\"}\n",
    "midas_weight = 0.3#@param {type:\"number\"}\n",
    "near_plane = 200#@param {type:\"number\"}\n",
    "far_plane = 10000#@param {type:\"number\"}\n",
    "fov = 40#@param {type:\"number\"}\n",
    "padding_mode = 'border'#@param {type:\"string\"}\n",
    "sampling_mode = 'bicubic'#@param {type:\"string\"}\n",
    "\n",
    "#======= TURBO MODE\n",
    "#@markdown ---\n",
    "#@markdown ####**Turbo Mode (3D anim only):**\n",
    "#@markdown (Starts after frame 10,) skips diffusion steps and just uses depth map to warp images for skipped frames.\n",
    "#@markdown Speeds up rendering by 2x-4x, and may improve image coherence between frames. frame_blend_mode smooths abrupt texture changes across 2 frames.\n",
    "#@markdown For different settings tuned for Turbo Mode, refer to the original Disco-Turbo Github: https://github.com/zippy731/disco-diffusion-turbo\n",
    "\n",
    "turbo_mode = False #@param {type:\"boolean\"}\n",
    "turbo_steps = \"3\" #@param [\"2\",\"3\",\"4\",\"5\",\"6\"] {type:\"string\"}\n",
    "turbo_preroll = 10 # frames\n",
    "\n",
    "#insist turbo be used only w 3d anim.\n",
    "if turbo_mode and animation_mode != '3D':\n",
    "  print('=====')\n",
    "  print('Turbo mode only available with 3D animations. Disabling Turbo.')\n",
    "  print('=====')\n",
    "  turbo_mode = False\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Coherency Settings:**\n",
    "#@markdown `frame_scale` tries to guide the new frame to looking like the old one. A good default is 1500.\n",
    "frames_scale = 1500 #@param{type: 'integer'}\n",
    "#@markdown `frame_skip_steps` will blur the previous frame - higher values will flicker less but struggle to add enough new detail to zoom into.\n",
    "frames_skip_steps = '60%' #@param ['40%', '50%', '60%', '70%', '80%'] {type: 'string'}\n",
    "\n",
    "#======= VR MODE\n",
    "#@markdown ---\n",
    "#@markdown ####**VR Mode (3D anim only):**\n",
    "#@markdown Enables stereo rendering of left/right eye views (supporting Turbo) which use a different (fish-eye) camera projection matrix.   \n",
    "#@markdown Note the images you're prompting will work better if they have some inherent wide-angle aspect\n",
    "#@markdown The generated images will need to be combined into left/right videos. These can then be stitched into the VR180 format.\n",
    "#@markdown Google made the VR180 Creator tool but subsequently stopped supporting it. It's available for download in a few places including https://www.patrickgrunwald.de/vr180-creator-download\n",
    "#@markdown The tool is not only good for stitching (videos and photos) but also for adding the correct metadata into existing videos, which is needed for services like YouTube to identify the format correctly.\n",
    "#@markdown Watching YouTube VR videos isn't necessarily the easiest depending on your headset. For instance Oculus have a dedicated media studio and store which makes the files easier to access on a Quest https://creator.oculus.com/manage/mediastudio/\n",
    "#@markdown \n",
    "#@markdown The command to get ffmpeg to concat your frames for each eye is in the form: `ffmpeg -framerate 15 -i frame_%4d_l.png l.mp4` (repeat for r)\n",
    "\n",
    "vr_mode = False #@param {type:\"boolean\"}\n",
    "#@markdown `vr_eye_angle` is the y-axis rotation of the eyes towards the center\n",
    "vr_eye_angle = 0.5 #@param{type:\"number\"}\n",
    "#@markdown interpupillary distance (between the eyes)\n",
    "vr_ipd = 5.0 #@param{type:\"number\"}\n",
    "\n",
    "#insist VR be used only w 3d anim.\n",
    "if vr_mode and animation_mode != '3D':\n",
    "  print('=====')\n",
    "  print('VR mode only available with 3D animations. Disabling VR.')\n",
    "  print('=====')\n",
    "  vr_mode = False\n",
    "\n",
    "\n",
    "def parse_key_frames(string, prompt_parser=None):\n",
    "    \"\"\"Given a string representing frame numbers paired with parameter values at that frame,\n",
    "    return a dictionary with the frame numbers as keys and the parameter values as the values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string: string\n",
    "        Frame numbers paired with parameter values at that frame number, in the format\n",
    "        'framenumber1: (parametervalues1), framenumber2: (parametervalues2), ...'\n",
    "    prompt_parser: function or None, optional\n",
    "        If provided, prompt_parser will be applied to each string of parameter values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Frame numbers as keys, parameter values at that frame number as values\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the input string does not match the expected format.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> parse_key_frames(\"10:(Apple: 1| Orange: 0), 20: (Apple: 0| Orange: 1| Peach: 1)\")\n",
    "    {10: 'Apple: 1| Orange: 0', 20: 'Apple: 0| Orange: 1| Peach: 1'}\n",
    "\n",
    "    >>> parse_key_frames(\"10:(Apple: 1| Orange: 0), 20: (Apple: 0| Orange: 1| Peach: 1)\", prompt_parser=lambda x: x.lower()))\n",
    "    {10: 'apple: 1| orange: 0', 20: 'apple: 0| orange: 1| peach: 1'}\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern = r'((?P<frame>[0-9]+):[\\s]*[\\(](?P<param>[\\S\\s]*?)[\\)])'\n",
    "    frames = dict()\n",
    "    for match_object in re.finditer(pattern, string):\n",
    "        frame = int(match_object.groupdict()['frame'])\n",
    "        param = match_object.groupdict()['param']\n",
    "        if prompt_parser:\n",
    "            frames[frame] = prompt_parser(param)\n",
    "        else:\n",
    "            frames[frame] = param\n",
    "\n",
    "    if frames == {} and len(string) != 0:\n",
    "        raise RuntimeError('Key Frame string not correctly formatted')\n",
    "    return frames\n",
    "\n",
    "def get_inbetweens(key_frames, integer=False):\n",
    "    \"\"\"Given a dict with frame numbers as keys and a parameter value as values,\n",
    "    return a pandas Series containing the value of the parameter at every frame from 0 to max_frames.\n",
    "    Any values not provided in the input dict are calculated by linear interpolation between\n",
    "    the values of the previous and next provided frames. If there is no previous provided frame, then\n",
    "    the value is equal to the value of the next provided frame, or if there is no next provided frame,\n",
    "    then the value is equal to the value of the previous provided frame. If no frames are provided,\n",
    "    all frame values are NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_frames: dict\n",
    "        A dict with integer frame numbers as keys and numerical values of a particular parameter as values.\n",
    "    integer: Bool, optional\n",
    "        If True, the values of the output series are converted to integers.\n",
    "        Otherwise, the values are floats.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        A Series with length max_frames representing the parameter values for each frame.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> max_frames = 5\n",
    "    >>> get_inbetweens({1: 5, 3: 6})\n",
    "    0    5.0\n",
    "    1    5.0\n",
    "    2    5.5\n",
    "    3    6.0\n",
    "    4    6.0\n",
    "    dtype: float64\n",
    "\n",
    "    >>> get_inbetweens({1: 5, 3: 6}, integer=True)\n",
    "    0    5\n",
    "    1    5\n",
    "    2    5\n",
    "    3    6\n",
    "    4    6\n",
    "    dtype: int64\n",
    "    \"\"\"\n",
    "    key_frame_series = pd.Series([np.nan for a in range(max_frames)])\n",
    "\n",
    "    for i, value in key_frames.items():\n",
    "        key_frame_series[i] = value\n",
    "    key_frame_series = key_frame_series.astype(float)\n",
    "    \n",
    "    interp_method = interp_spline\n",
    "\n",
    "    if interp_method == 'Cubic' and len(key_frames.items()) <=3:\n",
    "      interp_method = 'Quadratic'\n",
    "    \n",
    "    if interp_method == 'Quadratic' and len(key_frames.items()) <= 2:\n",
    "      interp_method = 'Linear'\n",
    "      \n",
    "    \n",
    "    key_frame_series[0] = key_frame_series[key_frame_series.first_valid_index()]\n",
    "    key_frame_series[max_frames-1] = key_frame_series[key_frame_series.last_valid_index()]\n",
    "    # key_frame_series = key_frame_series.interpolate(method=intrp_method,order=1, limit_direction='both')\n",
    "    key_frame_series = key_frame_series.interpolate(method=interp_method.lower(),limit_direction='both')\n",
    "    if integer:\n",
    "        return key_frame_series.astype(int)\n",
    "    return key_frame_series\n",
    "\n",
    "def split_prompts(prompts):\n",
    "  prompt_series = pd.Series([np.nan for a in range(max_frames)])\n",
    "  for i, prompt in prompts.items():\n",
    "    prompt_series[i] = prompt\n",
    "  # prompt_series = prompt_series.astype(str)\n",
    "  prompt_series = prompt_series.ffill().bfill()\n",
    "  return prompt_series\n",
    "\n",
    "if key_frames:\n",
    "    try:\n",
    "        angle_series = get_inbetweens(parse_key_frames(angle))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `angle` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `angle` as \"\n",
    "            f'\"0: ({angle})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        angle = f\"0: ({angle})\"\n",
    "        angle_series = get_inbetweens(parse_key_frames(angle))\n",
    "\n",
    "    try:\n",
    "        zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `zoom` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `zoom` as \"\n",
    "            f'\"0: ({zoom})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        zoom = f\"0: ({zoom})\"\n",
    "        zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
    "\n",
    "    try:\n",
    "        translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `translation_x` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `translation_x` as \"\n",
    "            f'\"0: ({translation_x})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        translation_x = f\"0: ({translation_x})\"\n",
    "        translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
    "\n",
    "    try:\n",
    "        translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `translation_y` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `translation_y` as \"\n",
    "            f'\"0: ({translation_y})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        translation_y = f\"0: ({translation_y})\"\n",
    "        translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
    "\n",
    "    try:\n",
    "        translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `translation_z` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `translation_z` as \"\n",
    "            f'\"0: ({translation_z})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        translation_z = f\"0: ({translation_z})\"\n",
    "        translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
    "\n",
    "    try:\n",
    "        rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `rotation_3d_x` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `rotation_3d_x` as \"\n",
    "            f'\"0: ({rotation_3d_x})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        rotation_3d_x = f\"0: ({rotation_3d_x})\"\n",
    "        rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
    "\n",
    "    try:\n",
    "        rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `rotation_3d_y` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `rotation_3d_y` as \"\n",
    "            f'\"0: ({rotation_3d_y})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        rotation_3d_y = f\"0: ({rotation_3d_y})\"\n",
    "        rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
    "\n",
    "    try:\n",
    "        rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            \"WARNING: You have selected to use key frames, but you have not \"\n",
    "            \"formatted `rotation_3d_z` correctly for key frames.\\n\"\n",
    "            \"Attempting to interpret `rotation_3d_z` as \"\n",
    "            f'\"0: ({rotation_3d_z})\"\\n'\n",
    "            \"Please read the instructions to find out how to use key frames \"\n",
    "            \"correctly.\\n\"\n",
    "        )\n",
    "        rotation_3d_z = f\"0: ({rotation_3d_z})\"\n",
    "        rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))\n",
    "\n",
    "else:\n",
    "    angle = float(angle)\n",
    "    zoom = float(zoom)\n",
    "    translation_x = float(translation_x)\n",
    "    translation_y = float(translation_y)\n",
    "    translation_z = float(translation_z)\n",
    "    rotation_3d_x = float(rotation_3d_x)\n",
    "    rotation_3d_y = float(rotation_3d_y)\n",
    "    rotation_3d_z = float(rotation_3d_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DefSecModel"
   },
   "source": [
    "### Extra Settings\n",
    " Partial Saves, Advanced Settings, Cutn Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DiffClipSetTop"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save every 21 steps\n"
     ]
    }
   ],
   "source": [
    "#@markdown ####**Saving:**\n",
    "\n",
    "intermediate_saves = 10#@param{type: 'raw'}\n",
    "intermediates_in_subfolder = True #@param{type: 'boolean'}\n",
    "#@markdown Intermediate steps will save a copy at your specified intervals. You can either format it as a single integer or a list of specific steps \n",
    "\n",
    "#@markdown A value of `2` will save a copy at 33% and 66%. 0 will save none.\n",
    "\n",
    "#@markdown A value of `[5, 9, 34, 45]` will save at steps 5, 9, 34, and 45. (Make sure to include the brackets)\n",
    "\n",
    "\n",
    "if type(intermediate_saves) is not list:\n",
    "  if intermediate_saves:\n",
    "    steps_per_checkpoint = math.floor((steps - skip_steps - 1) // (intermediate_saves+1))\n",
    "    steps_per_checkpoint = steps_per_checkpoint if steps_per_checkpoint > 0 else 1\n",
    "    print(f'Will save every {steps_per_checkpoint} steps')\n",
    "  else:\n",
    "    steps_per_checkpoint = steps+10\n",
    "else:\n",
    "  steps_per_checkpoint = None\n",
    "\n",
    "if intermediate_saves and intermediates_in_subfolder is True:\n",
    "  partialFolder = f'{batchFolder}/partials'\n",
    "  createPath(partialFolder)\n",
    "\n",
    "  #@markdown ---\n",
    "\n",
    "#@markdown ####**Advanced Settings:**\n",
    "#@markdown *There are a few extra advanced settings available if you double click this cell.*\n",
    "\n",
    "#@markdown *Perlin init will replace your init, so uncheck if using one.*\n",
    "\n",
    "perlin_init = False  #@param{type: 'boolean'}\n",
    "perlin_mode = 'mixed' #@param ['mixed', 'color', 'gray']\n",
    "set_seed = 'random_seed' #@param{type: 'string'}\n",
    "eta = 0.8#@param{type: 'number'}\n",
    "clamp_grad = True #@param{type: 'boolean'}\n",
    "clamp_max = 0.05 #@param{type: 'number'}\n",
    "\n",
    "\n",
    "### EXTRA ADVANCED SETTINGS:\n",
    "randomize_class = True\n",
    "clip_denoised = False\n",
    "fuzzy_prompt = False\n",
    "rand_mag = 0.05\n",
    "\n",
    "\n",
    " #@markdown ---\n",
    "\n",
    "#@markdown ####**Cutn Scheduling:**\n",
    "#@markdown Format: `[40]*400+[20]*600` = 40 cuts for the first 400 /1000 steps, then 20 for the last 600/1000\n",
    "\n",
    "#@markdown cut_overview and cut_innercut are cumulative for total cutn on any given step. Overview cuts see the entire image and are good for early structure, innercuts are your standard cutn.\n",
    "\n",
    "cut_overview = \"[12]*400+[4]*600\" #@param {type: 'string'}       \n",
    "cut_innercut =\"[4]*400+[12]*600\"#@param {type: 'string'}  \n",
    "cut_ic_pow = 1#@param {type: 'number'}  \n",
    "cut_icgray_p = \"[0.2]*400+[0]*600\"#@param {type: 'string'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ModelSettings"
   },
   "source": [
    "### Prompts\n",
    "`animation_mode: None` will only use the first set. `animation_mode: 2D / Video` will run through them per the set frames and hold on the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SettingsTop"
   },
   "outputs": [],
   "source": [
    "text_prompts = {\n",
    "    0: [\"A beautiful painting of a singular lighthouse, shining its light across a dense forest by greg rutkowski and thomas kinkade, Trending on artstation.:2\", \"a girl and a boy sit around a camp fire under the stars.:2\", \"blue color scheme:1\"],\n",
    "    100: [\"This set of prompts start at frame 100\",\"This prompt has weight five:5\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BasicSettings"
   },
   "outputs": [],
   "source": [
    "image_prompts = {\n",
    "    # 0:['ImagePromptsWorkButArentVeryGood.png:2',],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnimSetTop"
   },
   "source": [
    "# 4. Diffuse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AnimSettings"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c86f40911142ed80035e7bd47ccd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c377e077794b3991d284fb1a269acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f5a9bc578d49429663ffb274be7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed used: 2532599944\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Do the Run!\n",
    "#@markdown `n_batches` ignored with animation modes.\n",
    "display_rate =  25 #@param{type: 'number'}\n",
    "n_batches =  10 #@param{type: 'number'}\n",
    "\n",
    "#Update Model Settings\n",
    "timestep_respacing = f'ddim{steps}'\n",
    "diffusion_steps = (1000//steps)*steps if steps < 1000 else steps\n",
    "model_config.update({\n",
    "    'timestep_respacing': timestep_respacing,\n",
    "    'diffusion_steps': diffusion_steps,\n",
    "})\n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "def move_files(start_num, end_num, old_folder, new_folder):\n",
    "    for i in range(start_num, end_num):\n",
    "        old_file = old_folder + f'/{batch_name}({batchNum})_{i:04}.png'\n",
    "        new_file = new_folder + f'/{batch_name}({batchNum})_{i:04}.png'\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "\n",
    "resume_run = False #@param{type: 'boolean'}\n",
    "run_to_resume = 'latest' #@param{type: 'string'}\n",
    "resume_from_frame = 'latest' #@param{type: 'string'}\n",
    "retain_overwritten_frames = False #@param{type: 'boolean'}\n",
    "if retain_overwritten_frames is True:\n",
    "  retainFolder = f'{batchFolder}/retained'\n",
    "  createPath(retainFolder)\n",
    "\n",
    "\n",
    "skip_step_ratio = int(frames_skip_steps.rstrip(\"%\")) / 100\n",
    "calc_frames_skip_steps = math.floor(steps * skip_step_ratio)\n",
    "\n",
    "\n",
    "if steps <= calc_frames_skip_steps:\n",
    "  sys.exit(\"ERROR: You can't skip more steps than your total steps\")\n",
    "\n",
    "if resume_run:\n",
    "  if run_to_resume == 'latest':\n",
    "    try:\n",
    "      batchNum\n",
    "    except:\n",
    "      batchNum = len(glob(f\"{batchFolder}/{batch_name}(*)_settings.txt\"))-1\n",
    "  else:\n",
    "    batchNum = int(run_to_resume)\n",
    "  if resume_from_frame == 'latest':\n",
    "    start_frame = len(glob(batchFolder+f\"/{batch_name}({batchNum})_*.png\"))\n",
    "    if animation_mode != '3D' and turbo_mode == True and start_frame > turbo_preroll and start_frame % int(turbo_steps) != 0:\n",
    "      start_frame = start_frame - (start_frame % int(turbo_steps))\n",
    "  else:\n",
    "    start_frame = int(resume_from_frame)+1\n",
    "    if animation_mode != '3D' and turbo_mode == True and start_frame > turbo_preroll and start_frame % int(turbo_steps) != 0:\n",
    "      start_frame = start_frame - (start_frame % int(turbo_steps))\n",
    "    if retain_overwritten_frames is True:\n",
    "      existing_frames = len(glob(batchFolder+f\"/{batch_name}({batchNum})_*.png\"))\n",
    "      frames_to_save = existing_frames - start_frame\n",
    "      print(f'Moving {frames_to_save} frames to the Retained folder')\n",
    "      move_files(start_frame, existing_frames, batchFolder, retainFolder)\n",
    "else:\n",
    "  start_frame = 0\n",
    "  batchNum = len(glob(batchFolder+\"/*.txt\"))\n",
    "  while os.path.isfile(f\"{batchFolder}/{batch_name}({batchNum})_settings.txt\") is True or os.path.isfile(f\"{batchFolder}/{batch_name}-{batchNum}_settings.txt\") is True:\n",
    "    batchNum += 1\n",
    "\n",
    "print(f'Starting Run: {batch_name}({batchNum}) at frame {start_frame}')\n",
    "\n",
    "if set_seed == 'random_seed':\n",
    "    random.seed()\n",
    "    seed = random.randint(0, 2**32)\n",
    "    # print(f'Using seed: {seed}')\n",
    "else:\n",
    "    seed = int(set_seed)\n",
    "\n",
    "args = {\n",
    "    'batchNum': batchNum,\n",
    "    'prompts_series':split_prompts(text_prompts) if text_prompts else None,\n",
    "    'image_prompts_series':split_prompts(image_prompts) if image_prompts else None,\n",
    "    'seed': seed,\n",
    "    'display_rate':display_rate,\n",
    "    'n_batches':n_batches if animation_mode == 'None' else 1,\n",
    "    'batch_size':batch_size,\n",
    "    'batch_name': batch_name,\n",
    "    'steps': steps,\n",
    "    'diffusion_sampling_mode': diffusion_sampling_mode,\n",
    "    'width_height': width_height,\n",
    "    'clip_guidance_scale': clip_guidance_scale,\n",
    "    'tv_scale': tv_scale,\n",
    "    'range_scale': range_scale,\n",
    "    'sat_scale': sat_scale,\n",
    "    'cutn_batches': cutn_batches,\n",
    "    'init_image': init_image,\n",
    "    'init_scale': init_scale,\n",
    "    'skip_steps': skip_steps,\n",
    "    'side_x': side_x,\n",
    "    'side_y': side_y,\n",
    "    'timestep_respacing': timestep_respacing,\n",
    "    'diffusion_steps': diffusion_steps,\n",
    "    'animation_mode': animation_mode,\n",
    "    'video_init_path': video_init_path,\n",
    "    'extract_nth_frame': extract_nth_frame,\n",
    "    'video_init_seed_continuity': video_init_seed_continuity,\n",
    "    'key_frames': key_frames,\n",
    "    'max_frames': max_frames if animation_mode != \"None\" else 1,\n",
    "    'interp_spline': interp_spline,\n",
    "    'start_frame': start_frame,\n",
    "    'angle': angle,\n",
    "    'zoom': zoom,\n",
    "    'translation_x': translation_x,\n",
    "    'translation_y': translation_y,\n",
    "    'translation_z': translation_z,\n",
    "    'rotation_3d_x': rotation_3d_x,\n",
    "    'rotation_3d_y': rotation_3d_y,\n",
    "    'rotation_3d_z': rotation_3d_z,\n",
    "    'midas_depth_model': midas_depth_model,\n",
    "    'midas_weight': midas_weight,\n",
    "    'near_plane': near_plane,\n",
    "    'far_plane': far_plane,\n",
    "    'fov': fov,\n",
    "    'padding_mode': padding_mode,\n",
    "    'sampling_mode': sampling_mode,\n",
    "    'angle_series':angle_series,\n",
    "    'zoom_series':zoom_series,\n",
    "    'translation_x_series':translation_x_series,\n",
    "    'translation_y_series':translation_y_series,\n",
    "    'translation_z_series':translation_z_series,\n",
    "    'rotation_3d_x_series':rotation_3d_x_series,\n",
    "    'rotation_3d_y_series':rotation_3d_y_series,\n",
    "    'rotation_3d_z_series':rotation_3d_z_series,\n",
    "    'frames_scale': frames_scale,\n",
    "    'calc_frames_skip_steps': calc_frames_skip_steps,\n",
    "    'skip_step_ratio': skip_step_ratio,\n",
    "    'calc_frames_skip_steps': calc_frames_skip_steps,\n",
    "    'text_prompts': text_prompts,\n",
    "    'image_prompts': image_prompts,\n",
    "    'cut_overview': eval(cut_overview),\n",
    "    'cut_innercut': eval(cut_innercut),\n",
    "    'cut_ic_pow': cut_ic_pow,\n",
    "    'cut_icgray_p': eval(cut_icgray_p),\n",
    "    'intermediate_saves': intermediate_saves,\n",
    "    'intermediates_in_subfolder': intermediates_in_subfolder,\n",
    "    'steps_per_checkpoint': steps_per_checkpoint,\n",
    "    'perlin_init': perlin_init,\n",
    "    'perlin_mode': perlin_mode,\n",
    "    'set_seed': set_seed,\n",
    "    'eta': eta,\n",
    "    'clamp_grad': clamp_grad,\n",
    "    'clamp_max': clamp_max,\n",
    "    'skip_augs': skip_augs,\n",
    "    'randomize_class': randomize_class,\n",
    "    'clip_denoised': clip_denoised,\n",
    "    'fuzzy_prompt': fuzzy_prompt,\n",
    "    'rand_mag': rand_mag,\n",
    "}\n",
    "\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "print('Prepping model...')\n",
    "model, diffusion = create_model_and_diffusion(**model_config)\n",
    "model.load_state_dict(torch.load(f'{model_path}/{diffusion_model}.pt', map_location='cpu'))\n",
    "model.requires_grad_(False).eval().to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'qkv' in name or 'norm' in name or 'proj' in name:\n",
    "        param.requires_grad_()\n",
    "if model_config['use_fp16']:\n",
    "    model.convert_to_fp16()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "try:\n",
    "  do_run(args, model_path, gpu_device=DEVICE)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print('Seed used:', seed)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExtraSetTop"
   },
   "source": [
    "# 5. Create the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ExtraSettings"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 10\n",
      "b\"ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\\n  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\\n  configuration: --prefix=/home/kaihua/anaconda3 --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\\n  libavutil      56. 51.100 / 56. 51.100\\n  libavcodec     58. 91.100 / 58. 91.100\\n  libavformat    58. 45.100 / 58. 45.100\\n  libavdevice    58. 10.100 / 58. 10.100\\n  libavfilter     7. 85.100 /  7. 85.100\\n  libavresample   4.  0.  0 /  4.  0.  0\\n  libswscale      5.  7.100 /  5.  7.100\\n  libswresample   3.  7.100 /  3.  7.100\\nUnrecognized option 'crf'.\\nError splitting the argument list: Option not found\\n\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "b\"ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\\n  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\\n  configuration: --prefix=/home/kaihua/anaconda3 --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\\n  libavutil      56. 51.100 / 56. 51.100\\n  libavcodec     58. 91.100 / 58. 91.100\\n  libavformat    58. 45.100 / 58. 45.100\\n  libavdevice    58. 10.100 / 58. 10.100\\n  libavfilter     7. 85.100 /  7. 85.100\\n  libavresample   4.  0.  0 /  4.  0.  0\\n  libswscale      5.  7.100 /  5.  7.100\\n  libswresample   3.  7.100 /  3.  7.100\\nUnrecognized option 'crf'.\\nError splitting the argument list: Option not found\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10988/3725627458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The video is ready and saved to the images folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: b\"ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\\n  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\\n  configuration: --prefix=/home/kaihua/anaconda3 --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\\n  libavutil      56. 51.100 / 56. 51.100\\n  libavcodec     58. 91.100 / 58. 91.100\\n  libavformat    58. 45.100 / 58. 45.100\\n  libavdevice    58. 10.100 / 58. 10.100\\n  libavfilter     7. 85.100 /  7. 85.100\\n  libavresample   4.  0.  0 /  4.  0.  0\\n  libswscale      5.  7.100 /  5.  7.100\\n  libswresample   3.  7.100 /  3.  7.100\\nUnrecognized option 'crf'.\\nError splitting the argument list: Option not found\\n\""
     ]
    }
   ],
   "source": [
    "# @title ### **Create video**\n",
    "#@markdown Video file will save in the same folder as your images.\n",
    "\n",
    "skip_video_for_run_all = False #@param {type: 'boolean'}\n",
    "\n",
    "if skip_video_for_run_all == True:\n",
    "  print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
    "\n",
    "else:\n",
    "  # import subprocess in case this cell is run without the above cells\n",
    "  import subprocess\n",
    "  from base64 import b64encode\n",
    "\n",
    "  latest_run = batchNum\n",
    "\n",
    "  folder = batch_name #@param\n",
    "  run = latest_run #@param\n",
    "  final_frame = 'final_frame'\n",
    "\n",
    "\n",
    "  init_frame = 1#@param {type:\"number\"} This is the frame where the video will start\n",
    "  last_frame = final_frame#@param {type:\"number\"} You can change i to the number of the last frame you want to generate. It will raise an error if that number of frames does not exist.\n",
    "  fps = 12#@param {type:\"number\"}\n",
    "  # view_video_in_cell = True #@param {type: 'boolean'}\n",
    "\n",
    "  frames = []\n",
    "  # tqdm.write('Generating video...')\n",
    "\n",
    "  if last_frame == 'final_frame':\n",
    "    last_frame = len(glob(batchFolder+f\"/{folder}({run})_*.png\"))\n",
    "    print(f'Total frames: {last_frame}')\n",
    "\n",
    "  image_path = f\"{outDirPath}/{folder}/{folder}({run})_%04d.png\"\n",
    "  filepath = f\"{outDirPath}/{folder}/{folder}({run}).mp4\"\n",
    "\n",
    "\n",
    "  cmd = [\n",
    "      'ffmpeg',\n",
    "      '-y',\n",
    "      '-vcodec',\n",
    "      'png',\n",
    "      '-r',\n",
    "      str(fps),\n",
    "      '-start_number',\n",
    "      str(init_frame),\n",
    "      '-i',\n",
    "      image_path,\n",
    "      '-frames:v',\n",
    "      str(last_frame+1),\n",
    "      '-c:v',\n",
    "      'libx264',\n",
    "      '-vf',\n",
    "      f'fps={fps}',\n",
    "      '-pix_fmt',\n",
    "      'yuv420p',\n",
    "      '-crf',\n",
    "      '17',\n",
    "      '-preset',\n",
    "      'veryslow',\n",
    "      filepath\n",
    "  ]\n",
    "\n",
    "  process = subprocess.Popen(cmd, cwd=f'{batchFolder}', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  stdout, stderr = process.communicate()\n",
    "  if process.returncode != 0:\n",
    "      print(stderr)\n",
    "      raise RuntimeError(stderr)\n",
    "  else:\n",
    "      print(\"The video is ready and saved to the images folder\")\n",
    "\n",
    "  # if view_video_in_cell:\n",
    "  #     mp4 = open(filepath,'rb').read()\n",
    "  #     data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  #     display.HTML(f'<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PromptsTop"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Prompts"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiffuseTop"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoTheRun"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CreateVidTop"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CreateVid"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "CreditsChTop",
    "TutorialTop",
    "CheckGPU",
    "InstallDeps",
    "DefMidasFns",
    "DefFns",
    "DefSecModel",
    "DefSuperRes",
    "AnimSetTop",
    "ExtraSetTop"
   ],
   "machine_shape": "hm",
   "name": "Disco Diffusion v5.2 [w/ VR Mode]",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
