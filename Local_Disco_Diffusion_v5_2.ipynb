{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TitleTop"
   },
   "source": [
    "# 1. Check GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CreditsChTop"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 12 16:32:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:19:00.0 Off |                  N/A |\n",
      "| 44%   80C    P0   112W / 250W |      1MiB / 11019MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 29%   43C    P8     3W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:67:00.0 Off |                  N/A |\n",
      "| 46%   83C    P2   236W / 250W |   1847MiB / 11019MiB |     65%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:68:00.0 Off |                  N/A |\n",
      "| 50%   84C    P2   135W / 250W |   1872MiB / 11016MiB |     64%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2     21791      C   python                                      1835MiB |\n",
      "|    3      1570      G   /usr/lib/xorg/Xorg                             9MiB |\n",
      "|    3      1644      G   /usr/bin/gnome-shell                          14MiB |\n",
      "|    3     21615      C   python                                      1835MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "ECC features not supported for GPU 00000000:19:00.0.\n",
      "Treating as warning and moving on.\n",
      "All done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "#!nvidia-smi -i 0 -e 0\n",
    "nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(nvidiasmi_output)\n",
    "nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(nvidiasmi_ecc_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Credits"
   },
   "source": [
    "# 2. Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LicenseTop"
   },
   "outputs": [],
   "source": [
    "#@title 1.2 Prepare Folders\n",
    "import subprocess, os, sys\n",
    "import pathlib, shutil\n",
    "\n",
    "# the following paths are same as preprocessing.py\n",
    "root_path = os.getcwd()\n",
    "initDirPath = f'{root_path}/outputs/init_images'\n",
    "outDirPath = f'{root_path}/outputs/images_out'\n",
    "model_path = f'{root_path}/outputs/models'\n",
    "\n",
    "# project directory\n",
    "PROJECT_DIR = os.path.abspath(os.getcwd())\n",
    "sys.path.append(PROJECT_DIR)\n",
    "os.chdir(f'{PROJECT_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "License"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# import all dependencies\n",
    "from utils.utils_os import *\n",
    "preprocess(model_path, PROJECT_DIR)\n",
    "\n",
    "from utils.utils_functions import *\n",
    "from utils.utils_midas import *\n",
    "from utils.utils_video import *\n",
    "from main import do_run\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import gc\n",
    "import io\n",
    "import math\n",
    "import lpips\n",
    "from glob import glob\n",
    "from types import SimpleNamespace\n",
    "from CLIP import clip\n",
    "from guided_diffusion.script_util import create_model_and_diffusion, model_and_diffusion_defaults\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# If running locally, there's a good chance your env will need this in order to not crash upon np.matmul() or similar operations.\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "\n",
    "# AdaBins stuff\n",
    "MAX_ADABINS_AREA = 500000\n",
    "\n",
    "# CUDA Device\n",
    "DEVICE = torch.device('cuda:0' if (torch.cuda.is_available()) else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "device = DEVICE # At least one of the modules expects this name..\n",
    "\n",
    "\n",
    "if torch.cuda.get_device_capability(DEVICE) == (8,0): ## A100 fix thanks to Emad\n",
    "    print('Disabling CUDNN for A100 gpu', file=sys.stderr)\n",
    "    torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChangelogTop"
   },
   "source": [
    "# 3. Task Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Changelog"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "#####  Text Prompts  #####\n",
    "##########################\n",
    "# `animation_mode: None` will only use the first set. `animation_mode: 2D / Video` will run through them per the set frames and hold on the last one.\n",
    "\n",
    "text_prompts = {\n",
    "    0: [\"A beautiful painting of a singular lighthouse, shining its light across a dense forest by greg rutkowski and thomas kinkade, Trending on artstation.:2\", \n",
    "        \"a girl and a boy sit around a camp fire under the stars.:2\", \n",
    "        \"blue color scheme:1\"],\n",
    "    #100: [\"This set of prompts start at frame 100\",\"This prompt has weight five:5\"],\n",
    "}\n",
    "\n",
    "image_prompts = {\n",
    "    # 0:['ImagePromptsWorkButArentVeryGood.png:2',],\n",
    "}\n",
    "\n",
    "##########################\n",
    "## Important Parameters ##\n",
    "##########################\n",
    "\n",
    "#@markdown ####**Basic Settings:**\n",
    "batch_name = 'TimeToDisco2'\n",
    "steps = 250                  # [25,50,100,150,250,500,1000]\n",
    "width_height = [1280,768]\n",
    "clip_guidance_scale = 5000\n",
    "tv_scale =  0\n",
    "range_scale =   150\n",
    "sat_scale =   0\n",
    "cutn_batches = 4  \n",
    "skip_augs = False\n",
    "\n",
    "# *dispay rate and number of generated images*\n",
    "display_rate =  25 \n",
    "n_batches =  10 \n",
    "\n",
    "# *Init Settings:*\n",
    "# *Make sure you set skip_steps to ~50% of your steps if you want to use an init image.*\n",
    "init_image = None \n",
    "init_scale = 1000 \n",
    "skip_steps = 10 \n",
    "\n",
    "\n",
    "#Get corrected sizes\n",
    "side_x = (width_height[0]//64)*64;\n",
    "side_y = (width_height[1]//64)*64;\n",
    "if side_x != width_height[0] or side_y != width_height[1]:\n",
    "  print(f'Changing output size to {side_x}x{side_y}. Dimensions must by multiples of 64.')\n",
    "\n",
    "#Update Model Settings\n",
    "timestep_respacing = f'ddim{steps}'\n",
    "diffusion_steps = (1000//steps)*steps if steps < 1000 else steps\n",
    "\n",
    "#Make folder for batch\n",
    "batchFolder = f'{outDirPath}/{batch_name}'\n",
    "createPath(batchFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TutorialTop"
   },
   "source": [
    "# 4. Diffusion and CLIP model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DiffusionSet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 Model already downloaded, check check_model_SHA if the file is corrupt\n",
      "Secondary Model already downloaded, check check_model_SHA if the file is corrupt\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/kaihua/anaconda3/envs/disco_diffusion/lib/python3.7/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "#@markdown ####**Models Settings:**\n",
    "\n",
    "diffusion_model = \"512x512_diffusion_uncond_finetune_008100\"  # \"256x256_diffusion_uncond\" / \"512x512_diffusion_uncond_finetune_008100\"\n",
    "use_secondary_model = True \n",
    "diffusion_sampling_mode = 'ddim' # 'plms' / 'ddim'  \n",
    "\n",
    "use_checkpoint = True \n",
    "ViTB32 = True \n",
    "ViTB16 = True \n",
    "ViTL14 = False\n",
    "RN101 = False \n",
    "RN50 = True \n",
    "RN50x4 = False \n",
    "RN50x16 = False \n",
    "RN50x64 = False \n",
    "\n",
    "check_model_SHA = False\n",
    "\n",
    "download_models(model_path, check_model_SHA, diffusion_model, use_secondary_model)\n",
    "\n",
    "model_config = model_and_diffusion_defaults()\n",
    "model_config = update_diffusion_config(diffusion_model, model_config, use_checkpoint, timestep_respacing, diffusion_steps)\n",
    "model_default = model_config['image_size']\n",
    "\n",
    "if use_secondary_model:\n",
    "    secondary_model = SecondaryDiffusionImageNet2()\n",
    "    secondary_model.load_state_dict(torch.load(f'{model_path}/secondary_model_imagenet_2.pth', map_location='cpu'))\n",
    "    secondary_model.eval().requires_grad_(False).to(device)\n",
    "\n",
    "clip_models = []\n",
    "if ViTB32 is True: clip_models.append(clip.load('ViT-B/32', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if ViTB16 is True: clip_models.append(clip.load('ViT-B/16', jit=False)[0].eval().requires_grad_(False).to(device) ) \n",
    "if ViTL14 is True: clip_models.append(clip.load('ViT-L/14', jit=False)[0].eval().requires_grad_(False).to(device) ) \n",
    "if RN50 is True: clip_models.append(clip.load('RN50', jit=False)[0].eval().requires_grad_(False).to(device))\n",
    "if RN50x4 is True: clip_models.append(clip.load('RN50x4', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN50x16 is True: clip_models.append(clip.load('RN50x16', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN50x64 is True: clip_models.append(clip.load('RN50x64', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "if RN101 is True: clip_models.append(clip.load('RN101', jit=False)[0].eval().requires_grad_(False).to(device)) \n",
    "\n",
    "lpips_model = lpips.LPIPS(net='vgg').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SetupTop"
   },
   "source": [
    "# 5. Animation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CheckGPU"
   },
   "outputs": [],
   "source": [
    "# Animation Mode:\n",
    "#For animation, you probably want to turn `cutn_batches` to 1 to make it quicker.*\n",
    "\n",
    "animation_mode = 'None' # ['None', '2D', '3D', 'Video Input'] \n",
    "\n",
    "\n",
    "# Video Input Settings:\n",
    "video_init_path = \"training.mp4\"\n",
    "extract_nth_frame = 2 \n",
    "video_init_seed_continuity = True \n",
    "\n",
    "if animation_mode == \"Video Input\":\n",
    "  videoFramesFolder = f'videoFrames'\n",
    "  createPath(videoFramesFolder)\n",
    "  print(f\"Exporting Video Frames (1 every {extract_nth_frame})...\")\n",
    "  try:\n",
    "    for f in pathlib.Path(f'{videoFramesFolder}').glob('*.jpg'):\n",
    "      f.unlink()\n",
    "  except:\n",
    "    print('')\n",
    "  vf = f'select=not(mod(n\\,{extract_nth_frame}))'\n",
    "  subprocess.run(['ffmpeg', '-i', f'{video_init_path}', '-vf', f'{vf}', '-vsync', 'vfr', '-q:v', '2', '-loglevel', 'error', '-stats', f'{videoFramesFolder}/%04d.jpg'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "# 2D Animation Settings:\n",
    "# `zoom` is a multiplier of dimensions, 1 is no zoom.\n",
    "# All rotations are provided in degrees.\n",
    "\n",
    "key_frames = True \n",
    "max_frames = 10000\n",
    "\n",
    "if animation_mode == \"Video Input\":\n",
    "  max_frames = len(glob(f'{videoFramesFolder}/*.jpg'))\n",
    "\n",
    "interp_spline = 'Linear' #Do not change, currently will not look good. param ['Linear','Quadratic','Cubic']\n",
    "angle = \"0:(0)\"\n",
    "zoom = \"0: (1), 10: (1.05)\"\n",
    "translation_x = \"0: (0)\"\n",
    "translation_y = \"0: (0)\"\n",
    "translation_z = \"0: (10.0)\"\n",
    "rotation_3d_x = \"0: (0)\"\n",
    "rotation_3d_y = \"0: (0)\"\n",
    "rotation_3d_z = \"0: (0)\"\n",
    "midas_depth_model = \"dpt_large\"\n",
    "midas_weight = 0.3\n",
    "near_plane = 200\n",
    "far_plane = 10000\n",
    "fov = 40\n",
    "padding_mode = 'border'\n",
    "sampling_mode = 'bicubic'\n",
    "\n",
    "#======= TURBO MODE\n",
    "#@markdown ---\n",
    "#@markdown ####**Turbo Mode (3D anim only):**\n",
    "#@markdown (Starts after frame 10,) skips diffusion steps and just uses depth map to warp images for skipped frames.\n",
    "#@markdown Speeds up rendering by 2x-4x, and may improve image coherence between frames. frame_blend_mode smooths abrupt texture changes across 2 frames.\n",
    "#@markdown For different settings tuned for Turbo Mode, refer to the original Disco-Turbo Github: https://github.com/zippy731/disco-diffusion-turbo\n",
    "\n",
    "turbo_mode = False \n",
    "turbo_steps = \"3\"       # [\"2\",\"3\",\"4\",\"5\",\"6\"] \n",
    "turbo_preroll = 10 \n",
    "\n",
    "#insist turbo be used only w 3d anim.\n",
    "if turbo_mode and animation_mode != '3D':\n",
    "  print('=====')\n",
    "  print('Turbo mode only available with 3D animations. Disabling Turbo.')\n",
    "  print('=====')\n",
    "  turbo_mode = False\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Coherency Settings:**\n",
    "#@markdown `frame_scale` tries to guide the new frame to looking like the old one. A good default is 1500.\n",
    "#@markdown `frame_skip_steps` will blur the previous frame - higher values will flicker less but struggle to add enough new detail to zoom into.\n",
    "\n",
    "frames_scale = 1500 \n",
    "frames_skip_steps = '60%' # ['40%', '50%', '60%', '70%', '80%']\n",
    "\n",
    "#======= VR MODE\n",
    "#@markdown ---\n",
    "#@markdown ####**VR Mode (3D anim only):**\n",
    "#@markdown Enables stereo rendering of left/right eye views (supporting Turbo) which use a different (fish-eye) camera projection matrix.   \n",
    "#@markdown Note the images you're prompting will work better if they have some inherent wide-angle aspect\n",
    "#@markdown The generated images will need to be combined into left/right videos. These can then be stitched into the VR180 format.\n",
    "#@markdown Google made the VR180 Creator tool but subsequently stopped supporting it. It's available for download in a few places including https://www.patrickgrunwald.de/vr180-creator-download\n",
    "#@markdown The tool is not only good for stitching (videos and photos) but also for adding the correct metadata into existing videos, which is needed for services like YouTube to identify the format correctly.\n",
    "#@markdown Watching YouTube VR videos isn't necessarily the easiest depending on your headset. For instance Oculus have a dedicated media studio and store which makes the files easier to access on a Quest https://creator.oculus.com/manage/mediastudio/\n",
    "#@markdown \n",
    "#@markdown The command to get ffmpeg to concat your frames for each eye is in the form: `ffmpeg -framerate 15 -i frame_%4d_l.png l.mp4` (repeat for r)\n",
    "\n",
    "#@markdown `vr_eye_angle` is the y-axis rotation of the eyes towards the center\n",
    "#@markdown interpupillary distance (between the eyes)\n",
    "\n",
    "vr_mode = False\n",
    "vr_eye_angle = 0.5\n",
    "vr_ipd = 5.0\n",
    "\n",
    "#insist VR be used only w 3d anim.\n",
    "if vr_mode and animation_mode != '3D':\n",
    "  print('=====')\n",
    "  print('VR mode only available with 3D animations. Disabling VR.')\n",
    "  print('=====')\n",
    "  vr_mode = False\n",
    "    \n",
    "# parse parameters\n",
    "series_params, float_params = update_parameters(key_frames, max_frames, interp_spline, angle, zoom, translation_x, translation_y, translation_z,\n",
    "                                                  rotation_3d_x, rotation_3d_y, rotation_3d_z)\n",
    "angle_series, zoom_series, translation_x_series, translation_y_series, translation_z_series, rotation_3d_x_series, rotation_3d_y_series, rotation_3d_z_series = series_params\n",
    "angle, zoom, translation_x, translation_y, translation_z, rotation_3d_x, rotation_3d_y, rotation_3d_z = float_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "PrepFolders"
   },
   "source": [
    "# 6. Extra Settings\n",
    " Partial Saves, Advanced Settings, Cutn Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "InstallDeps"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save every 21 steps\n"
     ]
    }
   ],
   "source": [
    "#@markdown ####**Saving:**\n",
    "\n",
    "#@markdown Intermediate steps will save a copy at your specified intervals. You can either format it as a single integer or a list of specific steps \n",
    "#@markdown A value of `2` will save a copy at 33% and 66%. 0 will save none.\n",
    "#@markdown A value of `[5, 9, 34, 45]` will save at steps 5, 9, 34, and 45. (Make sure to include the brackets)\n",
    "\n",
    "intermediate_saves = 10 \n",
    "intermediates_in_subfolder = True  \n",
    "\n",
    "if type(intermediate_saves) is not list:\n",
    "  if intermediate_saves:\n",
    "    steps_per_checkpoint = math.floor((steps - skip_steps - 1) // (intermediate_saves+1))\n",
    "    steps_per_checkpoint = steps_per_checkpoint if steps_per_checkpoint > 0 else 1\n",
    "    print(f'Will save every {steps_per_checkpoint} steps')\n",
    "  else:\n",
    "    steps_per_checkpoint = steps+10\n",
    "else:\n",
    "  steps_per_checkpoint = None\n",
    "\n",
    "if intermediate_saves and intermediates_in_subfolder is True:\n",
    "  partialFolder = f'{batchFolder}/partials'\n",
    "  createPath(partialFolder)\n",
    "\n",
    "\n",
    "\n",
    "#@markdown ####**Advanced Settings:**\n",
    "#@markdown *There are a few extra advanced settings available if you double click this cell.*\n",
    "\n",
    "#@markdown *Perlin init will replace your init, so uncheck if using one.*\n",
    "\n",
    "perlin_init = False  \n",
    "perlin_mode = 'mixed' # ['mixed', 'color', 'gray']\n",
    "set_seed = 'random_seed'\n",
    "eta = 0.8\n",
    "clamp_grad = True\n",
    "clamp_max = 0.05\n",
    "\n",
    "\n",
    "### EXTRA ADVANCED SETTINGS:\n",
    "randomize_class = True\n",
    "clip_denoised = False\n",
    "fuzzy_prompt = False\n",
    "rand_mag = 0.05\n",
    "\n",
    "#@markdown ####**Cutn Scheduling:**\n",
    "#@markdown Format: `[40]*400+[20]*600` = 40 cuts for the first 400 /1000 steps, then 20 for the last 600/1000\n",
    "\n",
    "#@markdown cut_overview and cut_innercut are cumulative for total cutn on any given step. Overview cuts see the entire image and are good for early structure, innercuts are your standard cutn.\n",
    "\n",
    "cut_overview = \"[12]*400+[4]*600\" \n",
    "cut_innercut =\"[4]*400+[12]*600\"\n",
    "cut_ic_pow = 1\n",
    "cut_icgray_p = \"[0.2]*400+[0]*600\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DefMidasFns"
   },
   "source": [
    "# 7. Run Diffusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad87db49e2743c3a958a9d4cdf48cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53aa52537ce47c7b4cc248e700ef644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415159c4d0a246a7ba3b0cb3baae5f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Update Model Settings\n",
    "timestep_respacing = f'ddim{steps}'\n",
    "diffusion_steps = (1000//steps)*steps if steps < 1000 else steps\n",
    "model_config.update({\n",
    "    'timestep_respacing': timestep_respacing,\n",
    "    'diffusion_steps': diffusion_steps,\n",
    "})\n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "\n",
    "\n",
    "resume_run = False\n",
    "run_to_resume = 'latest'\n",
    "resume_from_frame = 'latest'\n",
    "retain_overwritten_frames = False\n",
    "if retain_overwritten_frames is True:\n",
    "  retainFolder = f'{batchFolder}/retained'\n",
    "  createPath(retainFolder)\n",
    "\n",
    "\n",
    "skip_step_ratio = int(frames_skip_steps.rstrip(\"%\")) / 100\n",
    "calc_frames_skip_steps = math.floor(steps * skip_step_ratio)\n",
    "\n",
    "\n",
    "if steps <= calc_frames_skip_steps:\n",
    "  sys.exit(\"ERROR: You can't skip more steps than your total steps\")\n",
    "\n",
    "if resume_run:\n",
    "  if run_to_resume == 'latest':\n",
    "    try:\n",
    "      batchNum\n",
    "    except:\n",
    "      batchNum = len(glob(f\"{batchFolder}/{batch_name}(*)_settings.txt\"))-1\n",
    "  else:\n",
    "    batchNum = int(run_to_resume)\n",
    "  if resume_from_frame == 'latest':\n",
    "    start_frame = len(glob(batchFolder+f\"/{batch_name}({batchNum})_*.png\"))\n",
    "    if animation_mode != '3D' and turbo_mode == True and start_frame > turbo_preroll and start_frame % int(turbo_steps) != 0:\n",
    "      start_frame = start_frame - (start_frame % int(turbo_steps))\n",
    "  else:\n",
    "    start_frame = int(resume_from_frame)+1\n",
    "    if animation_mode != '3D' and turbo_mode == True and start_frame > turbo_preroll and start_frame % int(turbo_steps) != 0:\n",
    "      start_frame = start_frame - (start_frame % int(turbo_steps))\n",
    "    if retain_overwritten_frames is True:\n",
    "      existing_frames = len(glob(batchFolder+f\"/{batch_name}({batchNum})_*.png\"))\n",
    "      frames_to_save = existing_frames - start_frame\n",
    "      print(f'Moving {frames_to_save} frames to the Retained folder')\n",
    "      move_files(start_frame, existing_frames, batchFolder, retainFolder, batch_name, batchNum)\n",
    "else:\n",
    "  start_frame = 0\n",
    "  batchNum = len(glob(batchFolder+\"/*.txt\"))\n",
    "  while os.path.isfile(f\"{batchFolder}/{batch_name}({batchNum})_settings.txt\") is True or os.path.isfile(f\"{batchFolder}/{batch_name}-{batchNum}_settings.txt\") is True:\n",
    "    batchNum += 1\n",
    "\n",
    "print(f'Starting Run: {batch_name}({batchNum}) at frame {start_frame}')\n",
    "\n",
    "if set_seed == 'random_seed':\n",
    "    random.seed()\n",
    "    seed = random.randint(0, 2**32)\n",
    "    # print(f'Using seed: {seed}')\n",
    "else:\n",
    "    seed = int(set_seed)\n",
    "\n",
    "args = {\n",
    "    'batchNum': batchNum,\n",
    "    'prompts_series':split_prompts(text_prompts, max_frames) if text_prompts else None,\n",
    "    'image_prompts_series':split_prompts(image_prompts, max_frames) if image_prompts else None,\n",
    "    'seed': seed,\n",
    "    'display_rate':display_rate,\n",
    "    'n_batches':n_batches if animation_mode == 'None' else 1,\n",
    "    'batch_size':batch_size,\n",
    "    'batch_name': batch_name,\n",
    "    'steps': steps,\n",
    "    'diffusion_sampling_mode': diffusion_sampling_mode,\n",
    "    'width_height': width_height,\n",
    "    'clip_guidance_scale': clip_guidance_scale,\n",
    "    'tv_scale': tv_scale,\n",
    "    'range_scale': range_scale,\n",
    "    'sat_scale': sat_scale,\n",
    "    'cutn_batches': cutn_batches,\n",
    "    'init_image': init_image,\n",
    "    'init_scale': init_scale,\n",
    "    'skip_steps': skip_steps,\n",
    "    'side_x': side_x,\n",
    "    'side_y': side_y,\n",
    "    'timestep_respacing': timestep_respacing,\n",
    "    'diffusion_steps': diffusion_steps,\n",
    "    'animation_mode': animation_mode,\n",
    "    'video_init_path': video_init_path,\n",
    "    'extract_nth_frame': extract_nth_frame,\n",
    "    'video_init_seed_continuity': video_init_seed_continuity,\n",
    "    'key_frames': key_frames,\n",
    "    'max_frames': max_frames if animation_mode != \"None\" else 1,\n",
    "    'interp_spline': interp_spline,\n",
    "    'start_frame': start_frame,\n",
    "    'angle': angle,\n",
    "    'zoom': zoom,\n",
    "    'translation_x': translation_x,\n",
    "    'translation_y': translation_y,\n",
    "    'translation_z': translation_z,\n",
    "    'rotation_3d_x': rotation_3d_x,\n",
    "    'rotation_3d_y': rotation_3d_y,\n",
    "    'rotation_3d_z': rotation_3d_z,\n",
    "    'midas_depth_model': midas_depth_model,\n",
    "    'midas_weight': midas_weight,\n",
    "    'near_plane': near_plane,\n",
    "    'far_plane': far_plane,\n",
    "    'fov': fov,\n",
    "    'padding_mode': padding_mode,\n",
    "    'sampling_mode': sampling_mode,\n",
    "    'angle_series':angle_series,\n",
    "    'zoom_series':zoom_series,\n",
    "    'translation_x_series':translation_x_series,\n",
    "    'translation_y_series':translation_y_series,\n",
    "    'translation_z_series':translation_z_series,\n",
    "    'rotation_3d_x_series':rotation_3d_x_series,\n",
    "    'rotation_3d_y_series':rotation_3d_y_series,\n",
    "    'rotation_3d_z_series':rotation_3d_z_series,\n",
    "    'frames_scale': frames_scale,\n",
    "    'frames_skip_steps': frames_skip_steps,\n",
    "    'skip_step_ratio': skip_step_ratio,\n",
    "    'calc_frames_skip_steps': calc_frames_skip_steps,\n",
    "    'text_prompts': text_prompts,\n",
    "    'image_prompts': image_prompts,\n",
    "    'cut_overview': eval(cut_overview),\n",
    "    'cut_innercut': eval(cut_innercut),\n",
    "    'cut_ic_pow': cut_ic_pow,\n",
    "    'cut_icgray_p': eval(cut_icgray_p),\n",
    "    'intermediate_saves': intermediate_saves,\n",
    "    'intermediates_in_subfolder': intermediates_in_subfolder,\n",
    "    'steps_per_checkpoint': steps_per_checkpoint,\n",
    "    'perlin_init': perlin_init,\n",
    "    'perlin_mode': perlin_mode,\n",
    "    'set_seed': set_seed,\n",
    "    'eta': eta,\n",
    "    'clamp_grad': clamp_grad,\n",
    "    'clamp_max': clamp_max,\n",
    "    'skip_augs': skip_augs,\n",
    "    'randomize_class': randomize_class,\n",
    "    'clip_denoised': clip_denoised,\n",
    "    'fuzzy_prompt': fuzzy_prompt,\n",
    "    'rand_mag': rand_mag,\n",
    "    'resume_run': resume_run,\n",
    "    'batchFolder': batchFolder,\n",
    "    'batch_name': batch_name,\n",
    "    'batchNum': batchNum,\n",
    "    'turbo_mode': turbo_mode,\n",
    "    'turbo_preroll': turbo_preroll,\n",
    "    'turbo_steps': turbo_steps,\n",
    "    'vr_mode': vr_mode,\n",
    "    'video_init_seed_continuity': video_init_seed_continuity,\n",
    "    'videoFramesFolder': videoFramesFolder if animation_mode == \"Video Input\" else None,\n",
    "    'clip_models': clip_models,\n",
    "    'use_secondary_model': use_secondary_model,\n",
    "    'partialFolder': partialFolder,\n",
    "}\n",
    "\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "print('Prepping model...')\n",
    "model, diffusion = create_model_and_diffusion(**model_config)\n",
    "model.load_state_dict(torch.load(f'{model_path}/{diffusion_model}.pt', map_location='cpu'))\n",
    "model.requires_grad_(False).eval().to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'qkv' in name or 'norm' in name or 'proj' in name:\n",
    "        param.requires_grad_()\n",
    "if model_config['use_fp16']:\n",
    "    model.convert_to_fp16()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "try:\n",
    "  do_run(args, diffusion, model,lpips_model, secondary_model, model_path, gpu_device=device)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print('Seed used:', seed)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ModelSettings"
   },
   "source": [
    "# 8. Create the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SettingsTop"
   },
   "outputs": [],
   "source": [
    "# @title ### **Create video**\n",
    "#@markdown Video file will save in the same folder as your images.\n",
    "\n",
    "skip_video_for_run_all = False #@param {type: 'boolean'}\n",
    "\n",
    "if skip_video_for_run_all == True:\n",
    "  print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
    "\n",
    "else:\n",
    "  # import subprocess in case this cell is run without the above cells\n",
    "  import subprocess\n",
    "  from base64 import b64encode\n",
    "\n",
    "  latest_run = batchNum\n",
    "\n",
    "  folder = batch_name #@param\n",
    "  run = latest_run #@param\n",
    "  final_frame = 'final_frame'\n",
    "\n",
    "\n",
    "  init_frame = 1#@param {type:\"number\"} This is the frame where the video will start\n",
    "  last_frame = final_frame#@param {type:\"number\"} You can change i to the number of the last frame you want to generate. It will raise an error if that number of frames does not exist.\n",
    "  fps = 12#@param {type:\"number\"}\n",
    "  # view_video_in_cell = True #@param {type: 'boolean'}\n",
    "\n",
    "  frames = []\n",
    "  # tqdm.write('Generating video...')\n",
    "\n",
    "  if last_frame == 'final_frame':\n",
    "    last_frame = len(glob(batchFolder+f\"/{folder}({run})_*.png\"))\n",
    "    print(f'Total frames: {last_frame}')\n",
    "\n",
    "  image_path = f\"{outDirPath}/{folder}/{folder}({run})_%04d.png\"\n",
    "  filepath = f\"{outDirPath}/{folder}/{folder}({run}).mp4\"\n",
    "\n",
    "\n",
    "  cmd = [\n",
    "      'ffmpeg',\n",
    "      '-y',\n",
    "      '-vcodec',\n",
    "      'png',\n",
    "      '-r',\n",
    "      str(fps),\n",
    "      '-start_number',\n",
    "      str(init_frame),\n",
    "      '-i',\n",
    "      image_path,\n",
    "      '-frames:v',\n",
    "      str(last_frame+1),\n",
    "      '-c:v',\n",
    "      'libx264',\n",
    "      '-vf',\n",
    "      f'fps={fps}',\n",
    "      '-pix_fmt',\n",
    "      'yuv420p',\n",
    "      '-crf',\n",
    "      '17',\n",
    "      '-preset',\n",
    "      'veryslow',\n",
    "      filepath\n",
    "  ]\n",
    "\n",
    "  process = subprocess.Popen(cmd, cwd=f'{batchFolder}', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  stdout, stderr = process.communicate()\n",
    "  if process.returncode != 0:\n",
    "      print(stderr)\n",
    "      raise RuntimeError(stderr)\n",
    "  else:\n",
    "      print(\"The video is ready and saved to the images folder\")\n",
    "\n",
    "  # if view_video_in_cell:\n",
    "  #     mp4 = open(filepath,'rb').read()\n",
    "  #     data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "  #     display.HTML(f'<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BasicSettings"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnimSettings",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Prompts"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoTheRun"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CreateVid"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "CreditsChTop",
    "TutorialTop",
    "CheckGPU",
    "InstallDeps",
    "DefMidasFns",
    "DefFns",
    "DefSecModel",
    "DefSuperRes",
    "AnimSetTop",
    "ExtraSetTop"
   ],
   "machine_shape": "hm",
   "name": "Disco Diffusion v5.2 [w/ VR Mode]",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
